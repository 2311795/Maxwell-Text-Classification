{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Job Description Multi-Label Classification\n",
    "This project implements a machine learning pipeline to classify job descriptions into multiple categories based on responses to a set of predefined questions. The model is trained using a multi-label classification approach, leveraging XGBoost classifier wrapped in a MultiOutputClassifier to handle the multiple outputs. The project also includes hyperparameter tuning using GridSearchCV to optimize model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\nosao\\desktop\\spacyproj\\spacy_venv\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\nosao\\desktop\\spacyproj\\spacy_venv\\lib\\site-packages (1.5.0)\n",
      "Requirement already satisfied: seaborn in c:\\users\\nosao\\desktop\\spacyproj\\spacy_venv\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: xgboost in c:\\users\\nosao\\desktop\\spacyproj\\spacy_venv\\lib\\site-packages (2.1.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\nosao\\desktop\\spacyproj\\spacy_venv\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\nosao\\desktop\\spacyproj\\spacy_venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\nosao\\desktop\\spacyproj\\spacy_venv\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\nosao\\desktop\\spacyproj\\spacy_venv\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\nosao\\desktop\\spacyproj\\spacy_venv\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\nosao\\desktop\\spacyproj\\spacy_venv\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\nosao\\desktop\\spacyproj\\spacy_venv\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\nosao\\desktop\\spacyproj\\spacy_venv\\lib\\site-packages (from seaborn) (3.8.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\nosao\\desktop\\spacyproj\\spacy_venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\nosao\\desktop\\spacyproj\\spacy_venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\nosao\\desktop\\spacyproj\\spacy_venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\nosao\\desktop\\spacyproj\\spacy_venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\nosao\\desktop\\spacyproj\\spacy_venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\nosao\\desktop\\spacyproj\\spacy_venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\nosao\\desktop\\spacyproj\\spacy_venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\nosao\\desktop\\spacyproj\\spacy_venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "C:\\Users\\nosao\\AppData\\Local\\Temp\\ipykernel_41456\\3733833754.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y[col] = le.fit_transform(y[col])  # Encode the target column\n",
      "C:\\Users\\nosao\\AppData\\Local\\Temp\\ipykernel_41456\\3733833754.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y[col] = le.fit_transform(y[col])  # Encode the target column\n",
      "C:\\Users\\nosao\\AppData\\Local\\Temp\\ipykernel_41456\\3733833754.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y[col] = le.fit_transform(y[col])  # Encode the target column\n",
      "C:\\Users\\nosao\\AppData\\Local\\Temp\\ipykernel_41456\\3733833754.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y[col] = le.fit_transform(y[col])  # Encode the target column\n",
      "C:\\Users\\nosao\\AppData\\Local\\Temp\\ipykernel_41456\\3733833754.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y[col] = le.fit_transform(y[col])  # Encode the target column\n",
      "c:\\Users\\nosao\\Desktop\\spacyProj\\spacy_venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "24 fits failed out of a total of 36.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "24 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nosao\\Desktop\\spacyProj\\spacy_venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\nosao\\Desktop\\spacyProj\\spacy_venv\\Lib\\site-packages\\sklearn\\multioutput.py\", line 544, in fit\n",
      "    super().fit(X, Y, sample_weight=sample_weight, **fit_params)\n",
      "  File \"c:\\Users\\nosao\\Desktop\\spacyProj\\spacy_venv\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\nosao\\Desktop\\spacyProj\\spacy_venv\\Lib\\site-packages\\sklearn\\multioutput.py\", line 279, in fit\n",
      "    self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\nosao\\Desktop\\spacyProj\\spacy_venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 67, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\nosao\\Desktop\\spacyProj\\spacy_venv\\Lib\\site-packages\\joblib\\parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "                                                ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\nosao\\Desktop\\spacyProj\\spacy_venv\\Lib\\site-packages\\joblib\\parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\nosao\\Desktop\\spacyProj\\spacy_venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 129, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\nosao\\Desktop\\spacyProj\\spacy_venv\\Lib\\site-packages\\sklearn\\multioutput.py\", line 68, in _fit_estimator\n",
      "    estimator.fit(X, y, **fit_params)\n",
      "  File \"c:\\Users\\nosao\\Desktop\\spacyProj\\spacy_venv\\Lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\nosao\\Desktop\\spacyProj\\spacy_venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1491, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1], got [0 2]\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\nosao\\Desktop\\spacyProj\\spacy_venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1052: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "c:\\Users\\nosao\\Desktop\\spacyProj\\spacy_venv\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [03:05:07] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Responses: {'Question 7': 'B', 'Question 8': 'C', 'Question 9': 'D', 'Question 10': 'C', 'Question 11': 'B'}\n",
      "Accuracy: 0.6333\n",
      "Precision: 0.7040\n",
      "Recall: 0.6167\n",
      "F1 Score: 0.5197\n"
     ]
    }
   ],
   "source": [
    "# pip is a package manager for Python libraries, and we use it to install the required libraries for this project.\n",
    "!pip install pandas scikit-learn seaborn xgboost\n",
    "# Import necessary libraries for data manipulation, feature extraction, model training, and evaluation\n",
    "import pandas as pd  # For data manipulation and analysis\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer  # For converting text data into TF-IDF features\n",
    "from sklearn.multioutput import MultiOutputClassifier  # For multi-label classification\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV  # For splitting data and hyperparameter tuning\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score  # For evaluating model performance\n",
    "import xgboost as xgb  # XGBoost classifier\n",
    "from sklearn.preprocessing import LabelEncoder  # For encoding target labels\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "# The dataset is expected to be a CSV file with job descriptions and responses to multiple questions.\n",
    "file_path = 'C:/Users/nosao/Desktop/Maxwell-Text Classification/Target Response/data/Target Response DB.csv'  # Update with your actual file path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Step 2: Encode the responses\n",
    "# Responses are encoded as integers for model compatibility.\n",
    "response_columns = ['Question 7', 'Question 8', 'Question 9', 'Question 10', 'Question 11']\n",
    "df_encoded = df.copy()\n",
    "\n",
    "# Map response labels 'A', 'B', 'C', 'D' to integers 0, 1, 2, 3 respectively\n",
    "response_mapping = {'A': 0, 'B': 1, 'C': 2, 'D': 3}\n",
    "reverse_mapping = {v: k for k, v in response_mapping.items()}  # Reverse mapping for decoding predictions later\n",
    "for col in response_columns:\n",
    "    df_encoded[col] = df_encoded[col].map(response_mapping)\n",
    "\n",
    "# Step 3: Split data into features and labels\n",
    "# 'Job description' is the feature, and the responses to the questions are the labels.\n",
    "X = df_encoded['Job description']  # Features: job descriptions\n",
    "y = df_encoded[response_columns]  # Labels: encoded responses to each question\n",
    "\n",
    "# Encode each label column to ensure class labels are continuous and start from 0\n",
    "label_encoders = {}\n",
    "for col in response_columns:\n",
    "    le = LabelEncoder()  # Initialize a LabelEncoder for each target column\n",
    "    y[col] = le.fit_transform(y[col])  # Encode the target column\n",
    "    label_encoders[col] = le  # Store the LabelEncoder for later use\n",
    "\n",
    "# Step 4: Text Preprocessing and Vectorization\n",
    "# Convert the job descriptions to TF-IDF features.\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2), stop_words='english')  # Use bigrams and remove common English stopwords\n",
    "X_vectorized = vectorizer.fit_transform(X)\n",
    "\n",
    "# Step 5: Split data into training and testing sets\n",
    "# The data is split into training (80%) and testing (20%) sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vectorized, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 6: Define the XGBClassifier model\n",
    "# XGBoost is a powerful gradient boosting model. We use it here as the base estimator.\n",
    "xgb_model = xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='mlogloss')\n",
    "\n",
    "# Step 7: Define the MultiOutputClassifier\n",
    "# MultiOutputClassifier allows us to apply the XGBoost model to multiple output labels (i.e., multiple questions).\n",
    "chain_model = MultiOutputClassifier(xgb_model)\n",
    "\n",
    "# Step 8: Define the hyperparameters grid\n",
    "# GridSearchCV will search over these hyperparameters to find the best model.\n",
    "param_grid = {\n",
    "    'estimator__n_estimators': [100, 200],  # Number of boosting rounds\n",
    "    'estimator__learning_rate': [0.01, 0.1],  # Learning rate for boosting\n",
    "    'estimator__max_depth': [3, 5, 7]  # Maximum depth of a tree\n",
    "}\n",
    "\n",
    "# Step 9: Initialize and perform Grid Search\n",
    "# GridSearchCV is used to perform an exhaustive search over the hyperparameters.\n",
    "grid_search_xgb = GridSearchCV(chain_model, param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "grid_search_xgb.fit(X_train, y_train)  # Fit the grid search to the training data\n",
    "\n",
    "# Get the best model from the grid search\n",
    "best_xgb_model = grid_search_xgb.best_estimator_\n",
    "\n",
    "# Step 10: Predict on the test set\n",
    "# Use the best model to make predictions on the test set.\n",
    "y_pred_xgb = best_xgb_model.predict(X_test)\n",
    "\n",
    "# Convert predictions to a DataFrame for easy manipulation and decoding\n",
    "predictions_xgb = pd.DataFrame(y_pred_xgb, columns=response_columns)\n",
    "\n",
    "# Decode the predictions back to the original labels (A, B, C, D)\n",
    "for col in response_columns:\n",
    "    predictions_xgb[col] = label_encoders[col].inverse_transform(predictions_xgb[col])\n",
    "\n",
    "# Step 11: Initialize metric dictionaries\n",
    "# These dictionaries will store evaluation metrics for each question.\n",
    "metrics = {\n",
    "    'accuracy': [],\n",
    "    'precision': [],\n",
    "    'recall': [],\n",
    "    'f1': []\n",
    "}\n",
    "\n",
    "# Decode y_test for evaluation\n",
    "for col in response_columns:\n",
    "    y_test[col] = label_encoders[col].inverse_transform(y_test[col])\n",
    "\n",
    "# Step 12: Calculate evaluation metrics for each question\n",
    "# Metrics calculated include accuracy, precision, recall, and F1 score.\n",
    "for i, col in enumerate(response_columns):\n",
    "    metrics['accuracy'].append(accuracy_score(y_test[col], predictions_xgb[col]))\n",
    "    metrics['precision'].append(precision_score(y_test[col], predictions_xgb[col], average='macro', zero_division=1))\n",
    "    metrics['recall'].append(recall_score(y_test[col], predictions_xgb[col], average='macro', zero_division=1))\n",
    "    metrics['f1'].append(f1_score(y_test[col], predictions_xgb[col], average='macro', zero_division=1))\n",
    "\n",
    "# Step 13: Average the metrics across all questions\n",
    "# Calculate the average of each metric across all questions.\n",
    "avg_metrics = {metric: sum(values) / len(values) for metric, values in metrics.items()}\n",
    "\n",
    "# Step 14: Adjust predictions based on a custom rule (assuming adjust_predictions is defined elsewhere)\n",
    "# Adjusted predictions may be modified based on a specific business rule or condition.\n",
    "# Define a function to adjust predictions based on a custom rule\n",
    "# This function adjusts the predictions such that once an 'A' is found, all preceding responses are set to 'D'.\n",
    "def adjust_predictions(predictions):\n",
    "    for index, row in predictions.iterrows():\n",
    "        main_focus_found = False\n",
    "        for col in reversed(predictions.columns):\n",
    "            if main_focus_found:\n",
    "                predictions.at[index, col] = 'D'  # Mark all preceding questions as 'D'\n",
    "            if row[col] == 'A':\n",
    "                main_focus_found = True\n",
    "    return predictions\n",
    "\n",
    "# Step 15: Adjust predictions using the custom rule\n",
    "adjusted_predictions = adjust_predictions(predictions_xgb.copy())\n",
    "\n",
    "# Step 16: Example prediction for a new job description\n",
    "# Predict responses for a new job description.\n",
    "new_description = [\"To provide of an effective Joinery resource to ensure the University fabric is efficiently maintained...\"]\n",
    "new_description_vectorized = vectorizer.transform(new_description)\n",
    "predictions_new = best_xgb_model.predict(new_description_vectorized)\n",
    "\n",
    "# Convert and decode the predictions for the new description\n",
    "predictions_new_df = pd.DataFrame(predictions_new, columns=response_columns)\n",
    "for col in response_columns:\n",
    "    predictions_new_df[col] = label_encoders[col].inverse_transform(predictions_new_df[col])\n",
    "\n",
    "# Adjust the new predictions based on the custom rule\n",
    "adjusted_predictions_new = adjust_predictions(predictions_new_df.copy())\n",
    "\n",
    "# Step 17: Decode the numeric predictions back to their original labels\n",
    "# Convert the adjusted predictions into the original response labels (A, B, C, D).\n",
    "decoded_predictions = {col: reverse_mapping[val] for col, val in adjusted_predictions_new.iloc[0].items()}\n",
    "print(\"Predicted Responses:\", decoded_predictions)\n",
    "\n",
    "# Step 18: Print evaluation metrics\n",
    "# Display the averaged accuracy, precision, recall, and F1 score.\n",
    "print(f\"Accuracy: {avg_metrics['accuracy']:.4f}\")\n",
    "print(f\"Precision: {avg_metrics['precision']:.4f}\")\n",
    "print(f\"Recall: {avg_metrics['recall']:.4f}\")\n",
    "print(f\"F1 Score: {avg_metrics['f1']:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Responses: {'Question 7': 'B', 'Question 8': 'B', 'Question 9': 'D', 'Question 10': 'B', 'Question 11': 'B'}\n",
      "Accuracy: 0.6333\n",
      "Precision: 0.7040\n",
      "Recall: 0.6167\n",
      "F1 Score: 0.5197\n"
     ]
    }
   ],
   "source": [
    "# Step 16: Example prediction for a new job description\n",
    "# Predict responses for a new job description.\n",
    "new_description = [\"To lead the procurement and sourcing function for Leeds Trinity University, ensuring all goods and services are sourced centrally or through agreed partners & approved routes, and that there is effective negotiation and supplier management both in the purchase and the monitoring of supplier performance. To liaise with the relevant purchasing consortia to achieve best value, to benchmark where appropriate and to market test certain activities.\"]\n",
    "new_description_vectorized = vectorizer.transform(new_description)\n",
    "predictions_new = best_xgb_model.predict(new_description_vectorized)\n",
    "\n",
    "# Convert and decode the predictions for the new description\n",
    "predictions_new_df = pd.DataFrame(predictions_new, columns=response_columns)\n",
    "for col in response_columns:\n",
    "    predictions_new_df[col] = label_encoders[col].inverse_transform(predictions_new_df[col])\n",
    "\n",
    "# Adjust the new predictions based on the custom rule\n",
    "adjusted_predictions_new = adjust_predictions(predictions_new_df.copy())\n",
    "\n",
    "# Step 17: Decode the numeric predictions back to their original labels\n",
    "# Convert the adjusted predictions into the original response labels (A, B, C, D).\n",
    "decoded_predictions = {col: reverse_mapping[val] for col, val in adjusted_predictions_new.iloc[0].items()}\n",
    "print(\"Predicted Responses:\", decoded_predictions)\n",
    "\n",
    "# Step 18: Print evaluation metrics\n",
    "# Display the averaged accuracy, precision, recall, and F1 score.\n",
    "print(f\"Accuracy: {avg_metrics['accuracy']:.4f}\")\n",
    "print(f\"Precision: {avg_metrics['precision']:.4f}\")\n",
    "print(f\"Recall: {avg_metrics['recall']:.4f}\")\n",
    "print(f\"F1 Score: {avg_metrics['f1']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spacy_kernel",
   "language": "python",
   "name": "spacy_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
